{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d37ee594",
   "metadata": {},
   "source": [
    "# Analysis of MF Data from AMFI and Portfolio Development\n",
    "\n",
    "This notebook aims to analyze all listed MFs under AMFI (Association of Mutual Funds of India) to provide insights on volatility and historical performance of each fund and leverage the same to suggest recommendations for investment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c167d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import neccessary libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Initialize environment\n",
    "load_dotenv()\n",
    "amfi_data_batchA = os.getenv('amfi_data_batchA')\n",
    "amfi_data_batchB = os.getenv('amfi_data_batchB')\n",
    "railway_db_url = os.getenv('railway_db_url')\n",
    "engine = create_engine(railway_db_url, connect_args={'options': '-c search_path=\"FINANCIAL_ANALYSIS\"'})\n",
    "\n",
    "# Select execution option\n",
    "option = input('Select program to run: 1-Data_Load, 2-Funds_Analysis: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d50fd94",
   "metadata": {},
   "source": [
    "## Data load program - to be executed only once in the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfbf7da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected option 2. Proceeding to execute funds analysis program.\n"
     ]
    }
   ],
   "source": [
    "# Data load program\n",
    "if option == '1':\n",
    "    try:\n",
    "        # Load data from batch A into dataframe and correct date format\n",
    "        df_batchA = pd.read_csv(amfi_data_batchA)\n",
    "        df_batchA['date'] = pd.to_datetime(df_batchA['date'], infer_datetime_format= True, errors = 'coerce')\n",
    "        print(f'Data for top 5 rows from batch A: \\n{df_batchA.head(5)}')\n",
    "        errors_batchA = df_batchA['date'].isna()\n",
    "        i_batchA = [rows for rows, val in enumerate(errors_batchA) if val == True]\n",
    "        print(f'Number of records with dates in string and not updated by Pandas in batch A: {len(i_batchA)}')\n",
    "        df_batchA = df_batchA.dropna(subset=['date'])\n",
    "        print(f'Number of records in batch A: {len(df_batchA['SNo.'])}')\n",
    "\n",
    "        # Load data from batch B into dataframe and correct date format\n",
    "        df_batchB = pd.read_csv(amfi_data_batchB)\n",
    "        df_batchB['date'] = pd.to_datetime(df_batchB['date'], infer_datetime_format= True, errors='coerce')\n",
    "        print(f'Data for top 5 rows from batch B: \\n{df_batchB.head(5)}')\n",
    "        errors_batchB = df_batchB['date'].isna()\n",
    "        i_batchB = [rows for rows, val in enumerate(errors_batchB) if val == True]\n",
    "        print(f'Number of records with dates in string and not updated by Pandas in batch B: {len(i_batchB)}')\n",
    "        df_batchB = df_batchB.dropna(subset=['date'])\n",
    "        print(f'Number of records in batch B: {len(df_batchB['SNo.'])}')\n",
    "\n",
    "        # Combine batch A and B data\n",
    "        df_combined = pd.concat([df_batchA, df_batchB], ignore_index=True)\n",
    "        df_combined = df_combined.rename(columns={'date': 'trx_date'})\n",
    "        df_combined = df_combined.rename(columns={'SNo.': 's_no'})\n",
    "        print(f'Data for top 5 rows from consolidated dataframe: \\n{df_combined.head(5)}')\n",
    "        print(f'Number of records in consolidated data: {len(df_combined['s_no'])}')\n",
    "\n",
    "        # Populate data into database\n",
    "        with engine.connect() as database_connection:\n",
    "            for records_start in range(0, len(df_combined), 1000000):\n",
    "                records_end = records_start + 1000000\n",
    "                df_chunks = df_combined.iloc[records_start:records_end]\n",
    "                df_chunks.to_sql(\n",
    "                    'amfi_database',\n",
    "                    con=database_connection,\n",
    "                    schema='FINANCIAL_ANALYSIS',\n",
    "                    if_exists='append',\n",
    "                    index=False,\n",
    "                    method='multi'\n",
    "                    )\n",
    "                database_connection.commit()\n",
    "                print(f'{len(df_chunks)} Committed.')\n",
    "\n",
    "        query = text('select * from amfi_database;')\n",
    "        with engine.connect() as database_connection:\n",
    "            df = pd.read_sql(sql=query, con=database_connection, index_col='trx_id')\n",
    "\n",
    "        processed_records = len(df['s_no'])\n",
    "        print(f'Successfully entered {processed_records} into database.')\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "else:\n",
    "    print(f'Selected option 2. Proceeding to execute funds analysis program.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c7d786",
   "metadata": {},
   "source": [
    "## Funds analysis program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4e36a2",
   "metadata": {},
   "source": [
    "### Data pull and initial analysis to record volatility and additional information using GPU enabled Data Frame (RAPIDS cuDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "387c89f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFs with available trading symbols:4702825\n",
      "20 year historical records: 4702825\n"
     ]
    }
   ],
   "source": [
    "# Funds analysis program - data pull and load\n",
    "if option == '2':\n",
    "    import cudf\n",
    "    import cupy as cp\n",
    "    import connectorx as cx\n",
    "    \n",
    "    try:\n",
    "        # Pull data into arrow table using connectorx and convert to GPU enabled dataframe.\n",
    "        query = 'select * from \"FINANCIAL_ANALYSIS\".amfi_database where trading_symbol_reinvestment is not null and trading_symbol_growth is not null;'\n",
    "        nav_historical_arrow_tbl = cx.read_sql(\n",
    "            conn=railway_db_url, \n",
    "            query=query, \n",
    "            return_type='arrow',\n",
    "            partition_on='trx_id',\n",
    "            partition_range=(1, 20000000),\n",
    "            partition_num=7\n",
    "            )\n",
    "        df_nav_historical_data = cudf.DataFrame.from_arrow(nav_historical_arrow_tbl)\n",
    "        df_nav_historical_data = df_nav_historical_data.sort_values(by='s_no')\n",
    "        print(f'MFs with available trading symbols:{len(df_nav_historical_data)}')\n",
    "        df_nav_historical_data_20_year = df_nav_historical_data[\n",
    "                df_nav_historical_data['trx_date'].dt.year>=2005\n",
    "            ]\n",
    "        print(f'20 year historical records: {len(df_nav_historical_data_20_year)}')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error Encountered: {e}')\n",
    "\n",
    "elif option == '1':\n",
    "    print('Selected option 1, running the data load program.')\n",
    "else:\n",
    "    print(f'Invalid option {option} selected. Please enter either 1 or 2 as input.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_rapids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
